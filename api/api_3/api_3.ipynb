{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from tqdm import tqdm\n",
    "from clickhouse_driver import Client\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: docker in /home/alexandr/.local/lib/python3.10/site-packages (7.1.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker) (2024.8.30)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: clickhouse_driver in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
      "Requirement already satisfied: pytz in /home/alexandr/.local/lib/python3.10/site-packages (from clickhouse_driver) (2024.2)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from clickhouse_driver) (5.2)\n",
      "docker: Error response from daemon: Conflict. The container name \"/clickhouse-server\" is already in use by container \"9e0ea3c268de4eb50e84255ebbae6719aeec84d9e1712fb037c46816b6034544\". You have to remove (or rename) that container to be able to reuse that name.\n",
      "See 'docker run --help'.\n"
     ]
    }
   ],
   "source": [
    "!pip install docker\n",
    "!pip install clickhouse_driver\n",
    "!docker run -d --name clickhouse-server --ulimit nofile=262144:262144 -p 9000:9000 yandex/clickhouse-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "\n",
    "url = 'https://books.toscrape.com/'\n",
    "user = UserAgent()\n",
    "headers = {\n",
    "    \"User-Agent\":user.random,\n",
    "}\n",
    "params = {}\n",
    "session = requests.session()\n",
    "response = session.get(url=url, params=params, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import clickhouse_connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('trips',)]\n"
     ]
    }
   ],
   "source": [
    "client = Client(host='localhost',\n",
    "                user='default',\n",
    "                password='',\n",
    "                port=9000\n",
    "                )\n",
    "\n",
    "\n",
    "try:\n",
    "    result = client.execute('SHOW TABLES')\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"Encountered an error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories_from_response(response):\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, features='html.parser')\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "    url_categories = []\n",
    "    result = soup.find_all(name=\"a\", attrs={\"href\":re.compile(\"^catalogue/category/books/\")})\n",
    "    for i in result:\n",
    "        url_categories.append(i.get(\"href\"))\n",
    "    url_categories_links = []\n",
    "    for i in url_categories:\n",
    "        url_categories_links.append(f'{url}{i}')\n",
    "    return url_categories_links\n",
    "\n",
    "url_categories_links = get_categories_from_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_from_row(url):\n",
    "    result = []\n",
    "    response = session.get(url=url, params=params, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, features='html.parser')\n",
    "    data_page_article = soup.find(name=\"ol\", attrs={\"class\":\"row\"}).find_all(name=\"h3\")\n",
    "    for card in data_page_article:\n",
    "        result.append(\"/\".join(url.split(\"/\")[:4]+(card.find(\"a\").get('href')).split(\"/\")[-2:]))\n",
    "    return result\n",
    "\n",
    "def urls_from_paginator(urls):\n",
    "        url_from_paginator = []\n",
    "        for url in tqdm(urls):\n",
    "                while url != None:\n",
    "                        response = session.get(url=url, params=params, headers=headers)\n",
    "                        soup = BeautifulSoup(response.text, features='html.parser')\n",
    "                        if soup.find(name=\"li\", attrs={\"class\":\"next\"}) is not None:\n",
    "                                next_lin=\"/\".join(url.split(\"/\")[:-1]+[soup.find(name=\"li\", attrs={\"class\":\"next\"}).findChild(\"a\").get(\"href\")])\n",
    "                                url_from_paginator.append(next_lin)\n",
    "                                url = next_lin\n",
    "                        else:\n",
    "                                url = None\n",
    "        result = url_from_paginator\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:12<00:00,  3.92it/s]\n"
     ]
    }
   ],
   "source": [
    "urls_paginator = urls_from_paginator(url_categories_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "50\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(len(urls_paginator))\n",
    "print(len(url_categories_links))\n",
    "url_categories_links.extend(urls_paginator)\n",
    "print(len(url_categories_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_books_links(urls):\n",
    "    finall_all_links = []\n",
    "    for url in tqdm(url_categories_links):\n",
    "        link_from_row = get_url_from_row(url)\n",
    "        finall_all_links.extend(link_from_row)\n",
    "    return finall_all_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:12<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "source": [
    "boks_links = all_books_links(url_categories_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraxt(url):\n",
    "    result = {}\n",
    "    response = session.get(url=url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, features='html.parser')\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "\n",
    "    card = soup.find(name=\"div\", attrs={\"class\":\"product_main\"})\n",
    "    if card:\n",
    "        result['name'] = card.find(name=\"h1\").text\n",
    "        price = card.find(name=\"p\", attrs={\"class\":\"price_color\"}).text\n",
    "        result['price'] = float(price[2:])\n",
    "        count = card.find(name=\"p\", attrs={\"class\":\"instock availability\"}).text\n",
    "        pattern = r'(\\d{1,9})'\n",
    "        count = int(re.search(pattern,count).group())\n",
    "        result['count'] = count\n",
    "    descriptions = soup.find(name=\"article\", attrs={\"class\":\"product_page\"}).find(name=\"p\", attrs={'class': False, 'id': False})\n",
    "    if descriptions:\n",
    "        result['description'] = descriptions.text\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name','price', 'count', 'description']\n",
    "result_data = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.execute(\n",
    "        '''\n",
    "        CREATE TABLE IF NOT EXISTS book\n",
    "        (\n",
    "            name String,\n",
    "            price String,\n",
    "            count String,\n",
    "            description String\n",
    "        )\n",
    "        ENGINE = MergeTree()\n",
    "        ORDER BY name;\n",
    "        '''\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name','price', 'count', 'description']\n",
    "result_data = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:34<00:00,  6.46it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, link in enumerate(tqdm(boks_links)):\n",
    "    data_page = data_extraxt(link)\n",
    "    result_data.loc[index] = data_page.get('name'), data_page.get('price'), data_page.get('count'), data_page.get('description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def code_dase64(text):\n",
    "    try:\n",
    "        if text is None:\n",
    "            text = 'None'\n",
    "        if type(text)!='str':\n",
    "            return base64.b64encode(str(text).encode(\"utf-8\")).hex()\n",
    "        return base64.b64encode(text.encode(\"utf-8\")).hex()\n",
    "    except:\n",
    "        print(f\"error convert data{text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:39<00:00,  6.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, link in enumerate(tqdm(boks_links)):\n",
    "    data_page = data_extraxt(link)\n",
    "    name = code_dase64(data_page.get('name'))\n",
    "    price = code_dase64(data_page.get('price'))\n",
    "    count = code_dase64(data_page.get('count'))\n",
    "    description = code_dase64(data_page.get('description'))\n",
    "    result = (name, price,count, description)\n",
    "    sql = f'''INSERT INTO book (*) VALUES ('{result[0]}','{result[1]}','{result[2]}','{result[3]}')'''\n",
    "    try:\n",
    "        client.execute(sql)\n",
    "    except:\n",
    "        print(f'error save {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   name         1000 non-null   object \n",
      " 1   price        1000 non-null   float64\n",
      " 2   count        1000 non-null   int64  \n",
      " 3   description  998 non-null    object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 39.1+ KB\n"
     ]
    }
   ],
   "source": [
    "result_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data['name'] = result_data['name'].astype('str')\n",
    "result_data['description'] = result_data['description'].astype('str')\n",
    "result_data['price'] = result_data['price'].astype('float64')\n",
    "result_data['count'] = result_data['count'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('book',), ('trips',)]"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.execute('SHOW TABLES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1000,)]"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.execute('SELECT count() FROM book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
